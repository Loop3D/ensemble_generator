{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "central-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "from perturber_func import perturb_interface, perturb_orient_vMF, perturb_fault_interface_vMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nervous-scotland",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "#      Names and labels     #\n",
    "#############################\n",
    "\n",
    "model_label = 'Geomodel_demo'\n",
    "source_geomodeller = True  # True or False\n",
    "#############################\n",
    "#           Paths           #\n",
    "#############################\n",
    "\n",
    "source_geomodeller=False\n",
    "path_to_geomodeller = 'C:/GeoModeller/GeoModeller4.0.7_x64_27eee3dc31ba'\n",
    "# path_to_geomodeller = pathlib.Path('C:\\GeoModeller\\GeoModeller4.0.8_x64_88b64e610d9')\n",
    "\n",
    "path_to_model = '../../map2loop2-notebooks/model-test/'\n",
    "# path_to_model_pl = pathlib.Path('C:/Users/Mark/Cloudstor/EGen/test_data3')\n",
    "path_to_scratch='../../map2loop2-notebooks/scratch/egen_runs'\n",
    "\n",
    "#############################\n",
    "#           Files           #\n",
    "#############################\n",
    "DEM=False\n",
    "DTM_name = 'dtm_rp.tif'  # , just the filename, not the path, includes file extension\n",
    "file_type='contacts'\n",
    "#############################\n",
    "#       Ensemble par        #\n",
    "#############################\n",
    "\n",
    "egen_runs = 1\n",
    "save_faults = True  # True/False: do we want faults included?\n",
    "\n",
    "#############################\n",
    "#       Voxet parameters    #\n",
    "#############################\n",
    "\n",
    "litho = True  # True or comment out\n",
    "scalar = False  # True or comment out\n",
    "scalar_grads = False  # True or comment out\n",
    "\n",
    "# Voxet parameters\n",
    "nx = 50\n",
    "ny = 50\n",
    "nz = 50\n",
    "\n",
    "#############################\n",
    "#      Perturbing params    #\n",
    "#############################\n",
    "\n",
    "# interface\n",
    "error_gps = 10\n",
    "distribution = 'uniform'\n",
    "DEM = False  # True or none\n",
    "# orientations\n",
    "kappa = 50\n",
    "error_gps = 10\n",
    "loc_distribution = 'uniform'\n",
    "\n",
    "#############################\n",
    "#       Compute params      #\n",
    "#############################\n",
    "\n",
    "series_list = 'all'  # list of series to calculate\n",
    "fault_list = 'all'  # (['Fault_12644', 'Fault_2235', 'Fault_11442', 'Fault_3496', 'Fault_5298', 'Fault_12647']) # list of faults to calculate or 'all'\n",
    "krig_range = None  # kriging range - set to None for default values\n",
    "interface = None  # nugget effect on interface; larger values = smoother model (less adherence to the data) default = 0.000001. Set to None for default value\n",
    "orientation = None  # nugget effect on orientation data; larger values = smoother model (less adherence to the data) default = 0.01. Set to None for default value\n",
    "drift = None  #\n",
    "\n",
    "#############################\n",
    "#       Summary stats       #\n",
    "#############################\n",
    "\n",
    "card = True  # True or False - export a voxet representing model cardinality\n",
    "ent = True  # True or False - export a voxet representing model entropy\n",
    "propor = True  # True or False - export a voxet representing the proportions of modelled lithologies\n",
    "export = True  # Export voxet - Can be 'False' if the arrays produced by the summary stats function are being passed directly to a downstream process\n",
    "air = True  # is there an 'air' layer in the model? Will be yes if there is a DTM and/or the surface topo is not at the top of the model volume. Important for geodiversity and proportion calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brave-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "egen_runs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "informative-orbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "if(not os.path.isdir(path_to_scratch+'/../gocad')):\n",
    "    os.mkdir(path_to_scratch+'/../gocad')\n",
    "\n",
    "for s in range(egen_runs):\n",
    "    path_to_scratch2=path_to_scratch+'_{0:06d}'.format(s)\n",
    "    if(not os.path.isdir(path_to_model+path_to_scratch2)):\n",
    "        os.mkdir(path_to_model+path_to_scratch2)\n",
    "    if(not os.path.isdir(path_to_model+path_to_scratch2+'/output')):\n",
    "        os.mkdir(path_to_model+path_to_scratch2+'/output')\n",
    "    if(not os.path.isdir(path_to_model+path_to_scratch2+'/tmp')):\n",
    "        os.mkdir(path_to_model+path_to_scratch2+'/tmp')\n",
    "    if(not os.path.isdir(path_to_model+path_to_scratch2+'/dtm')):\n",
    "        os.mkdir(path_to_model+path_to_scratch2+'/dtm')\n",
    "    if(not os.path.isdir(path_to_model+path_to_scratch2+'/vtk')):\n",
    "        os.mkdir(path_to_model+path_to_scratch2+'/vtk')\n",
    "\n",
    "files=[\n",
    "    'tmp/all_sorts_clean.csv','tmp/all_sorts_clean.csv', # (stratigraphy)\n",
    "    'tmp/raw_contacts.csv','tmp/raw_contacts.csv', # (undecimated contacts)\n",
    "    'output/contacts_{}.csv', 'output/contacts_clean.csv', #(all contacts)\n",
    "    'output/fault_displacements3.csv','output/fault_displacements3.csv', #(local estimates of fault displacements)\n",
    "    'output/faults.csv','output/faults.csv', #(fault trace info)\n",
    "    'output/fault_orientations_{}.csv','output/fault_orientations.csv', #(table of which faults truncate which other faults)\n",
    "    'output/fault-fault-relationships.csv','output/fault-fault-relationships.csv', #(table of which faults truncate which strat units)\n",
    "    'output/group-fault-relationships.csv','output/group-fault-relationships.csv', #(table of which faults truncate which strat units)\n",
    "    'output/fault_dimensions.csv','output/fault_dimensions.csv', #(fault extent ellipsoid data)\n",
    "    'output/fault_dimensions.csv','output/fault_dimensions.csv', #(fault orientationdata)\n",
    "    'tmp/super_groups.csv','tmp/super_groups.csv', #(which sets groups should be co-interpolated)\n",
    "    'tmp/bbox.csv','tmp/bbox.csv', # (bounding box in whatever metre-based projection system data is in)\n",
    "    'output/formation_summary_thicknesses.csv','output/formation_summary_thicknesses.csv', #(estimated summary formation thickness info)\n",
    "    'dtm/dtm_rp.tif','dtm/dtm_rp.tif', #(dtm as geotif, larger dimensions than bbox to make sure reprojected raster covers the whole area)\n",
    "    'tmp/bbox.csv','tmp/bbox.csv' # bounding box\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "smaller-trinity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../map2loop2-notebooks/model-test/output/orientations_0.csv\n",
      "../../map2loop2-notebooks/model-test/output/orientations_1.csv\n",
      "../../map2loop2-notebooks/model-test/output/orientations_2.csv\n",
      "../../map2loop2-notebooks/model-test/output/orientations_3.csv\n",
      "../../map2loop2-notebooks/model-test/output/orientations_4.csv\n",
      "../../map2loop2-notebooks/model-test/output/fault_orientations_0.csv\n",
      "../../map2loop2-notebooks/model-test/output/fault_orientations_1.csv\n",
      "../../map2loop2-notebooks/model-test/output/fault_orientations_2.csv\n",
      "../../map2loop2-notebooks/model-test/output/fault_orientations_3.csv\n",
      "../../map2loop2-notebooks/model-test/output/fault_orientations_4.csv\n"
     ]
    }
   ],
   "source": [
    "perturb_interface(path_to_model+'output',egen_runs, error_gps, file_type, loc_distribution, DEM, source_geomodeller)\n",
    "perturb_orient_vMF(path_to_model+'output',egen_runs, kappa, error_gps,file_type, loc_distribution, DEM, source_geomodeller)\n",
    "perturb_fault_interface_vMF(path_to_model+'output',egen_runs, kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "weighted-narrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No intrusive orientations available for merging.\n",
      "No intrusive orientations available for merging.\n",
      "No intrusive orientations available for merging.\n",
      "No intrusive orientations available for merging.\n",
      "No intrusive orientations available for merging.\n"
     ]
    }
   ],
   "source": [
    "pluton_form='domes'\n",
    "for s in range(egen_runs):\n",
    "    path_to_scratch2=path_to_scratch+'_{0:06d}'.format(s)+'/'\n",
    "    all_orientations = pd.read_csv(path_to_model+'output/orientations_{}.csv'.format(s),\",\")\n",
    "\n",
    "    if( os.path.exists(path_to_model+'output/ign_orientations_{}'+pluton_form.format(s)+'.csv')):\n",
    "        intrusive_orientations = pd.read_csv(path_to_model+'output/ign_orientations_'+pluton_form+'.csv',\",\")\n",
    "        all_orientations = pd.concat([all_orientations,intrusive_orientations],sort = False)\n",
    "    else:\n",
    "        print('No intrusive orientations available for merging.')\n",
    "    \n",
    "    all_orientations.to_csv(path_to_scratch2+'/output/orientations_clean.csv')\n",
    "    for a in range (0,int(len(files)),2):\n",
    "        #print(path_to_model+files[a],path_to_scratch+files[a+1])\n",
    "        shutil.copy2(path_to_model+files[a].format(s),path_to_scratch2+files[a+1])\n",
    "\n",
    "    #shutil.make_archive(path_to_scratch+'/../scratch', 'zip', path_to_scratch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "verified-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_vol_gocad(model, file_path,file_name, data_label, nsteps, real_coords=True):\n",
    "    \"\"\"\n",
    "    Writes out the model as a 3d volume grid in GOCAD VOXET object format\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : GeologicalModel object\n",
    "        Geological model to export\n",
    "    file_name : string\n",
    "        Name of file that model is exported to, including path, but without the file extension\n",
    "    data_label : string\n",
    "        A data label to insert into export file\n",
    "    nsteps : np.array([num-x-steps, num-y-steps, num-z-steps])\n",
    "        3d array dimensions\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    True if successful\n",
    "\n",
    "    \"\"\"\n",
    "    # Define grid spacing in model scale coords\n",
    "    loop_X = np.linspace(model.bounding_box[0, 0], model.bounding_box[1, 0], nsteps[0])\n",
    "    loop_Y = np.linspace(model.bounding_box[0, 1], model.bounding_box[1, 1], nsteps[1])\n",
    "    loop_Z = np.linspace(model.bounding_box[0, 2], model.bounding_box[1, 2], nsteps[2])\n",
    "\n",
    "    # Generate model values in 3d grid\n",
    "    xx, yy, zz = np.meshgrid(loop_X, loop_Y, loop_Z, indexing='ij')\n",
    "    # xyz is N x 3 vector array\n",
    "    xyz = np.array([xx.flatten(), yy.flatten(), zz.flatten()]).T\n",
    "    vals = model.evaluate_model(xyz, scale=False)\n",
    "    # Use FORTRAN style indexing for GOCAD VOXET\n",
    "    vol_vals = np.reshape(vals, nsteps, order='F')\n",
    "    bbox = model.bounding_box[:]\n",
    "        \n",
    "    # Convert bounding box to real world scale coords\n",
    "    if real_coords:\n",
    "        model.rescale(np.int64)\n",
    "    print(type(vals[0]))\n",
    "    # If integer values\n",
    "    if (type(vals[0]) is np.int64 or type(vals[0]) is np.int32 ):\n",
    "        d_type = np.int8\n",
    "        no_data_val = None\n",
    "        prop_esize = 1\n",
    "        prop_storage_type = \"Octet\"\n",
    "\n",
    "    # If float values\n",
    "    elif type(vals[0]) is np.float32:\n",
    "        d_type = np.dtype('>f4')\n",
    "        no_data_val = -999999.0\n",
    "        prop_esize = 4\n",
    "        prop_storage_type = \"Float\"\n",
    "    else:\n",
    "        print(\"Cannot export volume to GOCAD VOXET file: Unsupported type {}\".format(type(vals[0])))\n",
    "        return False\n",
    "\n",
    "    # Write out VOXET file\n",
    "    vo_filename = file_name + \".vo\"\n",
    "    data_filename = file_name + \"@@\"\n",
    "    try:\n",
    "        with open(file_path+vo_filename, \"w\") as fp:\n",
    "            fp.write(\"\"\"GOCAD Voxet 1\n",
    "HEADER {{\n",
    "name: {name}\n",
    "}}\n",
    "AXIS_O 0.000000 0.000000 0.000000\n",
    "AXIS_U 1.000000 0.000000 0.000000\n",
    "AXIS_V 0.000000 1.000000 0.000000\n",
    "AXIS_W 0.000000 0.000000 1.000000\n",
    "AXIS_MIN {axismin1} {axismin2} {axismin3}\n",
    "AXIS_MAX {axismax1} {axismax2} {axismax3}\n",
    "AXIS_N {nsteps1} {nsteps2} {nsteps3}\n",
    "AXIS_D {xdim} {ydim} {zdim}\n",
    "AXIS_NAME \"X\" \"Y\" \"Z\"\n",
    "AXIS_UNIT \"m\" \"m\" \"m\"\n",
    "AXIS_TYPE even even even\n",
    "PROPERTY 1 {propname}\n",
    "PROPERTY_CLASS 1 {propname}\n",
    "PROP_UNIT 1 {propname}\n",
    "PROPERTY_CLASS_HEADER 1 {propname} {{\n",
    "}}\n",
    "PROPERTY_SUBCLASS 1 QUANTITY {prop_storage_type}\n",
    "\"\"\".format(name=os.path.basename(file_name),\n",
    "                nsteps1=nsteps[0], nsteps2=nsteps[1], nsteps3=nsteps[2],\n",
    "                axismin1=bbox[0, 0], axismin2=bbox[0, 1], axismin3=bbox[0, 2],\n",
    "                axismax1=bbox[1, 0], axismax2=bbox[1, 1], axismax3=bbox[1, 2],\n",
    "                propname=data_label, prop_storage_type=prop_storage_type,\n",
    "                xdim=(bbox[0, 0]-bbox[1, 0])/nsteps[0],\n",
    "                ydim=(bbox[0, 1]-bbox[1, 1])/nsteps[1],\n",
    "                zdim=(bbox[0, 2]-bbox[1, 2])/nsteps[2]))\n",
    "            if no_data_val is not None:\n",
    "                fp.write(\"PROP_NO_DATA_VALUE 1 {no_data_val}\\n\".format(no_data_val=no_data_val))\n",
    "            fp.write(\"\"\"PROP_ETYPE 1 IEEE\n",
    "PROP_FORMAT 1 RAW\n",
    "PROP_ESIZE 1 {prop_esize}\n",
    "PROP_OFFSET 1 0\n",
    "PROP_FILE 1 {prop_file}\n",
    "END\\n\"\"\".format(prop_file=data_filename, prop_esize=prop_esize))\n",
    "    except IOError as exc:\n",
    "        print(\"Cannot export volume to GOCAD VOXET file {}: {}\".format(vo_filename, str(exc)))\n",
    "        return False\n",
    "\n",
    "    # Write out accompanying binary data file\n",
    "    export_vals = np.array(vol_vals, dtype=d_type)\n",
    "    try:\n",
    "        with open(file_path+data_filename, \"wb\") as fp:\n",
    "            export_vals.tofile(fp)\n",
    "    except IOError as exc:\n",
    "        print(\"Cannot export volume to GOCAD VOXET data file {}: {}\".format(data_filename, str(exc)))\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "public-arlington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../map2loop2-notebooks/scratch/egen_runs_000000/output/\n",
      "Updating geological model. There are: \n",
      "34 geological features that need to be interpolated\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b7cf45b1534bb5b25fa64f1d2ba4f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model update took: 38.98077630996704 seconds\n",
      "<class 'numpy.int32'>\n",
      "../../map2loop2-notebooks/scratch/egen_runs_000001/output/\n",
      "Updating geological model. There are: \n",
      "34 geological features that need to be interpolated\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdeebba62d304a0b86f9b7833ee40d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model update took: 26.773677110671997 seconds\n",
      "<class 'numpy.int32'>\n",
      "../../map2loop2-notebooks/scratch/egen_runs_000002/output/\n",
      "Updating geological model. There are: \n",
      "34 geological features that need to be interpolated\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab6f7818bea4656be4de69281d5dcb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model update took: 27.940638303756714 seconds\n",
      "<class 'numpy.int32'>\n",
      "../../map2loop2-notebooks/scratch/egen_runs_000003/output/\n",
      "Updating geological model. There are: \n",
      "34 geological features that need to be interpolated\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca4473169264076a52483bcfa545d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model update took: 27.153064727783203 seconds\n",
      "<class 'numpy.int32'>\n",
      "../../map2loop2-notebooks/scratch/egen_runs_000004/output/\n",
      "Updating geological model. There are: \n",
      "34 geological features that need to be interpolated\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc546f05a11646268d80596fc0b26f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model update took: 28.13924217224121 seconds\n",
      "<class 'numpy.int32'>\n"
     ]
    }
   ],
   "source": [
    "for s in range(egen_runs):\n",
    "    path_to_scratch2=path_to_scratch+'_{0:06d}'.format(s)\n",
    "    tmp_path=path_to_scratch2+'/tmp/'\n",
    "    vtk_path=path_to_scratch2+'/vtk/'\n",
    "    output_path=path_to_scratch2+'/output/'\n",
    "    dtm_path=path_to_scratch2+'/dtm/'\n",
    "    fault_file=path_to_scratch2+'/output/faults.csv'\n",
    "    test_data_path=path_to_scratch2\n",
    "    gocad_path=path_to_scratch2+'/../gocad/'\n",
    "    print(output_path)\n",
    "    if(True):\n",
    "        #model_base=-8200\n",
    "\n",
    "        import random\n",
    "        from datetime import datetime\n",
    "        from LoopStructural import GeologicalModel\n",
    "        import lavavu\n",
    "        from LoopStructural.visualisation import LavaVuModelViewer\n",
    "        from LoopStructural import GeologicalModel\n",
    "        import logging\n",
    "        logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "        nowtime=datetime.now().isoformat(timespec='minutes')   \n",
    "        model_name='leaflet'+'_'+nowtime.replace(\":\",\"-\").replace(\"T\",\"-\")\n",
    "        os.mkdir(vtk_path+model_name)\n",
    "        filename=vtk_path+model_name+'/'+'win_'+'surface_name_{}.vtk'\n",
    "\n",
    "\n",
    "        fault_params = {'interpolatortype':'FDI',\n",
    "                        'nelements':3e4,\n",
    "                        #'data_region':.3,\n",
    "                        'solver':'pyamg',\n",
    "        #                 overprints:overprints,\n",
    "                        'cpw':10,\n",
    "                        'npw':10}\n",
    "        foliation_params = {'interpolatortype':'FDI' , # 'interpolatortype':'PLI',\n",
    "                            'nelements':0.2e5,  # how many tetras/voxels\n",
    "                            'buffer':0.8,  # how much to extend nterpolation around box\n",
    "                            'solver':'pyamg',\n",
    "                            'damp':True}\n",
    "\n",
    "        if(not os.path.exists(fault_file)):\n",
    "            f=open(output_path + '/fault_displacements3.csv','w')\n",
    "            f.write('X,Y,fname,apparent_displacement,vertical_displacement,downthrow_dir\\n')\n",
    "            f.close()\n",
    "            f=open(output_path + '/fault_orientations.csv','w')\n",
    "            f.write('X,Y,Z,DipDirection,dip,DipPolarity,formation\\n')\n",
    "            f.close()\n",
    "            f=open(output_path + '/faults.csv','w')\n",
    "            f.write('X,Y,Z,formation\\n')\n",
    "            f.close()\n",
    "            f=open(output_path + '/fault-fault-relationships.csv','w')\n",
    "            f.write('fault_id\\n')\n",
    "            f.close()\n",
    "            f=open(output_path + '/group-fault-relationships.csv','w')\n",
    "            f.write('group\\n')\n",
    "            f.close()\n",
    "\n",
    "            model, m2l_data = GeologicalModel.from_map2loop_directory(test_data_path,\n",
    "                                                                  skip_faults=True,\n",
    "                                                                  fault_params=fault_params,\n",
    "                                                                  foliation_params=foliation_params)\n",
    "        else:\n",
    "            model, m2l_data = GeologicalModel.from_map2loop_directory(test_data_path,\n",
    "                                                                  skip_faults=False,\n",
    "                                                                  fault_params=fault_params,\n",
    "                                                                  foliation_params=foliation_params,\n",
    "                                                                  unconformities=True)\n",
    "\n",
    "        \"\"\"view = LavaVuModelViewer(model,vertical_exaggeration=2) \n",
    "        #view.set_zscale(2)\n",
    "        view.nsteps=np.array([50,50,50])\n",
    "        view.add_model_surfaces(filename=filename)\n",
    "        for sg in model.feature_name_index:\n",
    "            if( 'super' in sg):\n",
    "                view.add_data(model.features[model.feature_name_index[sg]])\n",
    "        #view.lv.webgl(vtk_path+model_name)\n",
    "        view.nsteps = np.array([200,200,200])\n",
    "        view.add_model()\n",
    "        view.interactive()  \"\"\"\n",
    "        write_vol_gocad(model, gocad_path,'GOCAD_LITHO'+'_{0:06d}'.format(s), 'lithology', [nx,ny,nz], real_coords=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "pharmaceutical-closure",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOCAD</td>\n",
       "      <td>Voxet</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEADER</td>\n",
       "      <td>{</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>name:</td>\n",
       "      <td>lithology_card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AXIS_O</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AXIS_U</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AXIS_V</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AXIS_W</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AXIS_MIN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AXIS_MAX</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5877194693752732</td>\n",
       "      <td>0.13600511192354375</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AXIS_N</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AXIS_D</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.011754389387505464</td>\n",
       "      <td>-0.0027201022384708753</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AXIS_NAME</td>\n",
       "      <td>X</td>\n",
       "      <td>Y</td>\n",
       "      <td>Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AXIS_UNIT</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AXIS_TYPE</td>\n",
       "      <td>even</td>\n",
       "      <td>even</td>\n",
       "      <td>even</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PROPERTY</td>\n",
       "      <td>1</td>\n",
       "      <td>'Cardinality'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PROPERTY_CLASS</td>\n",
       "      <td>1</td>\n",
       "      <td>'Cardinality'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PROP_UNIT</td>\n",
       "      <td>1</td>\n",
       "      <td>'Cardinality'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PROPERTY_CLASS_HEADER</td>\n",
       "      <td>1</td>\n",
       "      <td>'Cardinality'</td>\n",
       "      <td>{</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PROPERTY_SUBCLASS</td>\n",
       "      <td>1</td>\n",
       "      <td>QUANTITY</td>\n",
       "      <td>Octet</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PROP_ETYPE</td>\n",
       "      <td>1</td>\n",
       "      <td>IEEE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PROP_FORMAT</td>\n",
       "      <td>1</td>\n",
       "      <td>RAW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PROP_ESIZE</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PROP_OFFSET</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PROP_FILE</td>\n",
       "      <td>1</td>\n",
       "      <td>lithology_card.vop1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>END</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0               1                      2  \\\n",
       "0                   GOCAD           Voxet                      1   \n",
       "1                  HEADER               {                    NaN   \n",
       "2                   name:  lithology_card                    NaN   \n",
       "3                       }             NaN                    NaN   \n",
       "4                  AXIS_O        0.000000               0.000000   \n",
       "5                  AXIS_U        1.000000               0.000000   \n",
       "6                  AXIS_V        0.000000               1.000000   \n",
       "7                  AXIS_W        0.000000               0.000000   \n",
       "8                AXIS_MIN             0.0                    0.0   \n",
       "9                AXIS_MAX             1.0     0.5877194693752732   \n",
       "10                 AXIS_N              50                     50   \n",
       "11                 AXIS_D           -0.02  -0.011754389387505464   \n",
       "12              AXIS_NAME               X                      Y   \n",
       "13              AXIS_UNIT               m                      m   \n",
       "14              AXIS_TYPE            even                   even   \n",
       "15               PROPERTY               1          'Cardinality'   \n",
       "16         PROPERTY_CLASS               1          'Cardinality'   \n",
       "17              PROP_UNIT               1          'Cardinality'   \n",
       "18  PROPERTY_CLASS_HEADER               1          'Cardinality'   \n",
       "19                      }             NaN                    NaN   \n",
       "20      PROPERTY_SUBCLASS               1               QUANTITY   \n",
       "21             PROP_ETYPE               1                   IEEE   \n",
       "22            PROP_FORMAT               1                    RAW   \n",
       "23             PROP_ESIZE               1                      4   \n",
       "24            PROP_OFFSET               1                      0   \n",
       "25              PROP_FILE               1    lithology_card.vop1   \n",
       "26                    END             NaN                    NaN   \n",
       "\n",
       "                         3   4  \n",
       "0                      NaN NaN  \n",
       "1                      NaN NaN  \n",
       "2                      NaN NaN  \n",
       "3                      NaN NaN  \n",
       "4                 0.000000 NaN  \n",
       "5                 0.000000 NaN  \n",
       "6                 0.000000 NaN  \n",
       "7                 1.000000 NaN  \n",
       "8                      0.0 NaN  \n",
       "9      0.13600511192354375 NaN  \n",
       "10                      50 NaN  \n",
       "11  -0.0027201022384708753 NaN  \n",
       "12                       Z NaN  \n",
       "13                       m NaN  \n",
       "14                    even NaN  \n",
       "15                     NaN NaN  \n",
       "16                     NaN NaN  \n",
       "17                     NaN NaN  \n",
       "18                       { NaN  \n",
       "19                     NaN NaN  \n",
       "20                   Octet NaN  \n",
       "21                     NaN NaN  \n",
       "22                     NaN NaN  \n",
       "23                     NaN NaN  \n",
       "24                     NaN NaN  \n",
       "25                     NaN NaN  \n",
       "26                     NaN NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%% import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from math import log, e\n",
    "import sys, os, glob\n",
    "from stats_utils import entropy_custom\n",
    "from stats_utils import litho_probabilites\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "def stats_gocad_voxet(directory, type, model_label='Anon', card=False, ent=False, propor=False, export=True, air=False):\n",
    "    # i want to specify the voxet name too, but first let's test just using the directory name\n",
    "    #type = c(\"Card_VOXET\", \"Entropy_VOXET\", \"Frequency_VOXET\", \"OLS_VOXET\", \"P1_VOXET\", \"GOCAD_LITHO\")\n",
    "    # this function imports voxets that are output by Geomodeller and related CURE (Common Uncertainty Research Explorer).\n",
    "    # while these voxets are technically \"Gocad\" format, true Gocad format has @@ prefixes to properties\n",
    "    # So this reader won't work with true gocad formats (yet).\n",
    "    #print(str(os.getcwd()))\n",
    "    #os.chdir(directory)\n",
    "    #print(os.getcwd())\n",
    "    \n",
    "    pattern = type\n",
    "    if type == \"GOCAD_LITHO\":\n",
    "        pattern_a = \"*\"\n",
    "    elif type == \"gocad_litho\":\n",
    "        pattern_a = \"*\"\n",
    "    else:\n",
    "        pattern_a = type\n",
    "    # generate list of voxet header files to import\n",
    "    h_pattern = directory+pattern_a + pattern + \"*.vo\"\n",
    "    header_file = glob.glob(h_pattern)\n",
    "\n",
    "    if len(header_file) != 0:\n",
    "        # this reads the first file listed from the dir() operation, but I don't like it much. I'd prefer to specify\n",
    "        # the header explicitly, but I can't seem to get the regex within the pattern arg working properly\n",
    "        # \"Frequency_VOXET.vo\\W\" works in the regex util, but not in R... who knows.\n",
    "\n",
    "        # gocad header voxets have varying number of columns down the file. This process\n",
    "        # dynamically generates the number of columns so the head can be imported as a csv\n",
    "\n",
    "        # The max column count a line in the file could have\n",
    "        largest_column_count = 0\n",
    "\n",
    "        with open(header_file[0], 'r') as temp_h:\n",
    "            # read lines\n",
    "            lines = temp_h.readlines()\n",
    "\n",
    "            for l in lines:\n",
    "                # Count the column count for the current line\n",
    "                column_count = len(l.split(' ')) + 1\n",
    "\n",
    "                # Set the new most column count\n",
    "                largest_column_count = column_count if largest_column_count < column_count else largest_column_count\n",
    "\n",
    "        #Close the file\n",
    "        temp_h.close()\n",
    "\n",
    "        # Generate column names (will be 0, 1, 2, ..., largest_column_count - 1)\n",
    "        column_names = [i for i in range(0, largest_column_count)]\n",
    "\n",
    "        # Read csv\n",
    "        full_header = pd.read_csv(header_file[0], header=None, delimiter=\" \", names=column_names)\n",
    "\n",
    "        #full_header = pd.read_csv(header_file[0], header=None, sep=\" \")\n",
    "        header = pd.read_csv(header_file[0], header=None, sep=\" \", skiprows=4, nrows=8)\n",
    "        header_units = pd.read_csv(header_file[0], header=None, sep=\" \", skiprows=13, nrows=1)\n",
    "    else:\n",
    "        print(\"Unknown voxet type: please enter voxet filename without the file extension\")\n",
    "        sys.exit()\n",
    "\n",
    "    # create file names for export\n",
    "    card_file_name = model_label + '_card'\n",
    "    ent_file_name = model_label + '_entropy'\n",
    "    # proportion file names set in the export loop below\n",
    "\n",
    "\n",
    "    #create headers for different exports\n",
    "    card_header = full_header.copy(deep=True) # interesting - need to do a deep copy. Normal copy will produce a new dataframe linked to the orginal. Changes to the original will be reflected in the copies.\n",
    "    ent_header = full_header.copy(deep=True) # interesting - need to do a deep copy. Normal copy will produce a new dataframe linked to the orginal. Changes to the original will be reflected in the copies.\n",
    "    propor_header = full_header.copy(deep=True)\n",
    "\n",
    "    # format header info - cardinality\n",
    "    card_header.loc[2, 1] = card_file_name\n",
    "    card_header.loc[15, 2] = \"'Cardinality'\"\n",
    "    card_header.loc[16, 2] = \"'Cardinality'\"\n",
    "    card_header.loc[17, 2] = \"'Cardinality'\"\n",
    "    card_header.loc[18, 2] = \"'Cardinality'\"\n",
    "    card_header.loc[23, 2] = \"4\"\n",
    "    card_header.loc[25, 2] = card_file_name + '.vop1'\n",
    "\n",
    "    # format header info - entropy\n",
    "    ent_header.loc[2, 1] = ent_file_name\n",
    "    ent_header.loc[15, 2] = \"'Entropy'\"\n",
    "    ent_header.loc[16, 2] = \"'Entropy'\"\n",
    "    ent_header.loc[17, 2] = \"'Entropy'\"\n",
    "    ent_header.loc[18, 2] = \"'Entropy'\"\n",
    "    ent_header.loc[23, 2] = \"4\"\n",
    "    ent_header.loc[25, 2] = ent_file_name + '.vop1'\n",
    "\n",
    "    #list the voxet property binary files to import\n",
    "    # generate list of voxet header files to import\n",
    "    p_pattern = directory+pattern_a + pattern + \"*@@\"\n",
    "    prop_files = glob.glob(p_pattern)\n",
    "    litho_df = pd.DataFrame(np.zeros([int(header.loc[6,1]*header.loc[6,2]*header.loc[6,3]), 1]))\n",
    "\n",
    "    \n",
    "    for f in range(len(prop_files)):\n",
    "        data = np.fromfile(prop_files[f], '>i1') # import binary with format '>f4': '>' = big endian, 'f' float, '4' size\n",
    "\n",
    "        litho_df[f] = pd.DataFrame(data) # assign data to df column\n",
    "    litho_df.columns = [prop_files] # label columns with model name\n",
    "    # issue - the original voxet export includes 'air' - lithoID = 0, the recalculated model voxets do not.\n",
    "    # we want air to be included, esp for geophys. So we create an 'air' mask using df indices where 0.0\n",
    "    if air is True:\n",
    "        air_idx = litho_df[[f'orig_{type}.vop1']] == 0.0\n",
    "        idx = air_idx\n",
    "        for i in range(litho_df.shape[1]-1): # subtract 1 from iterator because we start with one row\n",
    "            air_idx = np.concatenate([air_idx, idx], axis=1)\n",
    "        litho_df[air_idx] = 0.0\n",
    "\n",
    "\n",
    "    # calculate cardinality\n",
    "    # simple operation - how many unique values in each row.\n",
    "    if card is True:\n",
    "        card_data = litho_df.nunique(1)\n",
    "        if export is True:\n",
    "            card_export = np.array(card_data, '>f4')\n",
    "            card_export.tofile(directory+card_file_name + '.vop1')\n",
    "            card_header.to_csv(directory+card_file_name + \".vo\", sep=\" \", na_rep=\"\", header=False, index=False)\n",
    "\n",
    "    #calculate entropy\n",
    "    if ent is True:\n",
    "        ent_data = litho_df.apply(entropy_custom, axis=1)\n",
    "        if export is True:\n",
    "            ent_export = np.array(ent_data, '>f4')\n",
    "            ent_export.tofile(directory+ent_file_name + '.vop1')\n",
    "            ent_header.to_csv(directory+ent_file_name + \".vo\", sep=\" \", na_rep=\"\", header=False, index=False)\n",
    "\n",
    "    #calculate frequency\n",
    "    if propor is True:\n",
    "        propor_data = litho_probabilites(litho_df)\n",
    "        if export is True:\n",
    "            propor_block_template = propor_header.copy(deep=True)[15:26]\n",
    "            propor_header = propor_header.drop(propor_header.index[15:27])\n",
    "            propor_header.loc[2, 1] = f'''{model_label}_proportions'''\n",
    "            propor_header_file_name = f'''{model_label}_propor.vo'''\n",
    "            #propor_file_name = propor_header.drop(propor_header.index[15:26])\n",
    "            for v in range(1, propor_data.shape[0]):\n",
    "                property_file_name = f'''{model_label}_propor_{v}.vop1'''\n",
    "                propor_block_tmp = propor_block_template.copy(deep=True)\n",
    "                propor_block_tmp.loc[15:18,1]=v\n",
    "                propor_block_tmp.loc[20:25, 1] = v\n",
    "                propor_block_tmp.loc[15, 2] = f'''Proportion_lith_{v}'''\n",
    "                propor_block_tmp.loc[16, 2] = f'''Proportion_lith_{v}'''\n",
    "                propor_block_tmp.loc[17, 2] = f'''Proportion_lith_{v}'''\n",
    "                propor_block_tmp.loc[18, 2] = f'''Proportion_lith_{v}'''\n",
    "                propor_block_tmp.loc[23, 2] = 4\n",
    "                propor_block_tmp.loc[25, 2] = property_file_name\n",
    "                propor_header = propor_header.append(propor_block_tmp)\n",
    "                propor_export = np.array(propor_data.loc[v], '>f4')\n",
    "                propor_export.tofile(directory+property_file_name)\n",
    "            propor_header.to_csv(directory+propor_header_file_name, sep=\" \", na_rep=\"\", header=False, index=False)\n",
    "\n",
    "    return litho_df, card_data, ent_data, propor_data\n",
    "\n",
    "\n",
    "\n",
    "#%% export summary stats to voxet\n",
    "\n",
    "# def export_gocad_voxet(dataframe, path, type):\n",
    "#      '''exports a dataframe to gocad voxet binary\n",
    "#      'dataframe' is the pandas dataframe to be exported as voxet\n",
    "#      'path' is the export path\n",
    "#      'type' is the type of voxet - this defines the export name: \"cardinality\", \"entropy\", \"probability\"'''\n",
    "#      #write header\n",
    "#\n",
    "#      #write binary\n",
    "#\n",
    "#\n",
    "#      coords = np.zeros([int(header.loc[6,1]*header.loc[6,2]*header.loc[6,3]), 3])\n",
    "#      coords_ref =\n",
    "#\n",
    "# def writeCFloat(f, ndarray):\n",
    "#     np.asarray(ndarray, dtype=np.float32).tofile(f)\n",
    "# def writeCInt(f, ndarray):\n",
    "#     np.asarray(ndarray, dtype=np.int32).tofile(f)\n",
    "# def writeC80(f, string):\n",
    "#     np.asarray(string, dtype='a80').tofile(f)\n",
    "#\n",
    "# if __name__ == \"__main__\":\n",
    "#     f = open('test.out', mode='wb')\n",
    "#     ndarray = np.zeros((10000,10000))\n",
    "#\n",
    "#     writeCInt(f, ndarray)\n",
    "#     writeCFloat(f, ndarray)\n",
    "#     writeC80(f, 'coordinates')\n",
    "\n",
    "#%% visualisation (put in different py file)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#   #build voxet in x, y, z order\n",
    "#   coords <- matrix(NA, nrow = header[7,2]*header[7,3]*header[7,4], ncol = 3)\n",
    "#   coords_ref <- list(z = seq(header[5,4], header[6,4], header[8,4]), y = seq(header[5,3], header[6,3], header[8,3]), x = seq(header[5,2], header[6,2], header[8,2]))\n",
    "#   l=0\n",
    "#   for (i in 1:header[7,4]){ #then build z-axis\n",
    "#     for (j in 1:header[7,3]){ #then build y-axis\n",
    "#       for (k in 1:header[7,2]){ #build x-axis first\n",
    "#         l <- l+1\n",
    "#         coords[l,] <- c(coords_ref$x[k], coords_ref$y[j], coords_ref$z[i])\n",
    "#       }\n",
    "#     }\n",
    "#   }\n",
    "#   # combine all property vectors into a dataframe\n",
    "#   r_grid <- data.frame(coords, data.frame(sapply(prop_files, function(x) get(x))))\n",
    "#   # rename coords columns in spatstat expectation i.e. lower case \"x\", \"y\", \"z\"\n",
    "#   names(r_grid)[names(r_grid)==\"X1\"] <- \"x\"\n",
    "#   names(r_grid)[names(r_grid)==\"X2\"] <- \"y\"\n",
    "#   names(r_grid)[names(r_grid)==\"X3\"] <- \"z\"\n",
    "#\n",
    "#   temp_list <- list(header = header, header_units = header_units, data = r_grid)\n",
    "#   #eval(parse(paste(\"r_grid_\", type, sep=\"\")) <- r_grid) # return grid with type in name\n",
    "#   return(temp_list)\n",
    "# }\n",
    "#\n",
    "#\n",
    "litho_df, card_data, ent_data, propor_data=stats_gocad_voxet(gocad_path, 'GOCAD_LITHO', model_label='lithology', card=True, ent=True, propor=True, export=True, air=False)\n",
    "\n",
    "# i want to specify the voxet name too, but first let's test just using the directory name\n",
    "#type = c(\"Card_VOXET\", \"Entropy_VOXET\", \"Frequency_VOXET\", \"OLS_VOXET\", \"P1_VOXET\", \"GOCAD_LITHO\")\n",
    "# this function imports voxets that are output by Geomodeller and related CURE (Common Uncertainty Research Explorer).\n",
    "# while these voxets are technically \"Gocad\" format, true Gocad format has @@ prefixes to properties\n",
    "# So this reader won't work with true gocad formats (yet).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dated-mother",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.03464"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stock-shopping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020071461737071437"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cooked-claim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.090909\n",
       "1         0.090909\n",
       "2         0.090909\n",
       "3         0.090909\n",
       "4         0.090909\n",
       "            ...   \n",
       "124995    0.090909\n",
       "124996    0.090909\n",
       "124997    0.090909\n",
       "124998    0.090909\n",
       "124999    0.090909\n",
       "Length: 125000, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propor_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-fields",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
